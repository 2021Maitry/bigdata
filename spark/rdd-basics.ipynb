{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var linesRdd = sc.textFile(\"/data/mr/wordcount/input/big.txt\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var localarr = linesRdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "localarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linesRdd.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linesRdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var words = linesRdd.flatMap(x => x.split(\" \"))\n",
    "var wordsKv = words.map(x => (x, 1))\n",
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordsKv.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordsKv.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "//def myfunc(x:Int, y:Int): Int = x + y\n",
    "var output = wordsKv.reduceByKey(_ + _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.saveAsTextFile(\"my_result_23dec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(words.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val arr = 1 to 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 17..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val nums = sc.parallelize(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[43] at parallelize at <console>:16"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiplyByTwo(x:Int):Int = x*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiplyByTwo(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var dbls = nums.map(multiplyByTwo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var dbls = nums.map(x => x*2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2, 4, 6, 8, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbls.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4) MapPartitionsRDD[45] at map at <console>:18 []\n",
       " |  ParallelCollectionRDD[43] at parallelize at <console>:16 []"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbls.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var localdata = dbls.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222, 224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250, 252, 254, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276, 278, 280, 282, 284, 286, 288, 290, 292, 294, 296, 298, 300, 302, 304, 306, 308, 310, 312, 314, 316, 318, 320, 322, 324, 326, 328, 330,..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isEven(x:Int):Boolean = x%20 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var evennums = nums.filter(isEven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(20, 40, 60, 80, 100, 120, 140, 160, 180, 200)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evennums.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var x = 4+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var arr = 1 to 1000\n",
    "var nums = sc.parallelize(arr)\n",
    "def isEven(x:Int):Array[Int] = {\n",
    "  if(x%2 == 0) Array(x)\n",
    "  else Array()\n",
    "}\n",
    "var evens = nums.flatMap(isEven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222, 224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250, 252, 254, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276, 278, 280, 282, 284, 286, 288, 290, 292, 294, 296, 298, 300, 302, 304, 306, 308, 310, 312, 314, 316, 318, 320, 322, 324, 326, 328, 330,..."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evens.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isEven(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isEven(x:Int) = if(x%2 == 0) Array(x) else Array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isEven(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:20: error: polymorphic expression cannot be instantiated to expected type;\n",
       " found   : [T]Array[T]\n",
       " required: TraversableOnce[?]\n",
       "       var evens = nums.flatMap(x => if(x%2 == 0) Array(x) else Array())\n",
       "                                                                     ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var evens = nums.flatMap(x => if(x%2 == 0) Array(x) else Array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var a = sc.parallelize(Array('1','2','3'), 2);\n",
    "var b = sc.parallelize(Array('A','B','C', 'C'));\n",
    "var c=a.union(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1, 2, 3, A, B, C, C)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.partitions.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1, 2, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(org.apache.spark.rdd.ParallelCollectionPartition@f0e, org.apache.spark.rdd.ParallelCollectionPartition@f0f, org.apache.spark.rdd.ParallelCollectionPartition@f10, org.apache.spark.rdd.ParallelCollectionPartition@f11)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:15: error: not enough arguments for method textFile: (path: String, minPartitions: Int)org.apache.spark.rdd.RDD[String].\n",
       "Unspecified value parameter path.\n",
       "              sc.textFile() // load data from HDFS\n",
       "                         ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile() // load data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// urls.txt - 1 million records \n",
    "//one url in each line - 100 bytes. 100 MB\n",
    "var urlrdd = sc.textFile(\"url.txt\", 2000);\n",
    "//we have 500 machine each having 4 executor = 2000 executors \n",
    "// ~ 500 urls per machine\n",
    "\n",
    "def downloadURL(url:String) = {....}\n",
    "var result = urlrdd.map(downloadURL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// fibonachi series\n",
    "// Every number is sum of previous two numebers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var seq = sc.parallelize(1 to 10000, 20)\n",
    "def add(x: Int, y:Int):Int = {return x+y}\n",
    "var total = seq.reduce(add);\n",
    "total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:17: error: value add is not a member of org.apache.spark.rdd.RDD[Int]\n",
       "              seq.add\n",
       "                  ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Number of tasks == partitions\n",
    "// Each executor can run some amount of tasks\n",
    "// The number of partittion can be decided by us or by spark\n",
    "// 7.7 GB\n",
    "// spark-shell --master yarn\n",
    "\n",
    "var file = sc.textFile(\"/data/msprojects/in_table.csv\");\n",
    "\n",
    "var hights = file.map(x => x.split(\",\")(1))\n",
    "\n",
    "var filtered = hights.filter(x => x != \"block_height\")\n",
    "\n",
    "var intheights = filtered.map(x => x.toInt)\n",
    "\n",
    "def maxheights(x:Int, y:Int) = if(x > y) x else y\n",
    "intheights.reduce(maxheights)\n",
    "\n",
    "1254137\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var rdd = sc.parallelize(Array(1.0,2,3, 4, 5 , 6, 7), 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var avg = rdd.reduce(_ + _) / rdd.count();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var rdd = sc.parallelize(Array(1.0,2,3, 4, 5 , 6, 7), 3);\n",
    "var rdd_count = rdd.map((_, 1))\n",
    "var (sum, count) = rdd_count.reduce((x, y) => (x._1 + y._1, x._2 + y._2))\n",
    "var avg = sum / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[13] at map at <console>:16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var x = rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "var x = (3,1)\n",
    "var y = (5,1)\n",
    "\n",
    "println(x._1 + y._1)\n",
    "println(x._2 + y._2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var rdd = sc.parallelize(Array(2, 3, 5, 6))\n",
    "\n",
    "//Mean or average of numbers is μ \n",
    "var rdd_count = rdd.map((_, 1))\n",
    "var (sum, count) = rdd_count.reduce((x, y) => (x._1 + y._1, x._2 + y._2))\n",
    "var avg = sum / count\n",
    "\n",
    "// (xi - μ)2\n",
    "var diffs = rdd.map( _ - avg)\n",
    "var sqdiff = diffs.map(x => x*x)\n",
    "\n",
    "// ∑(xi - μ)2\n",
    "var sum_sqdiff = sqdiff.reduce(_ + _)\n",
    "\n",
    "//√1/N ∑(xi - μ)2\n",
    "import math._;\n",
    "var sd = sqrt(sum_sqdiff*1.0/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:14: error: not found: value sd\n",
       "              sd\n",
       "              ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//sd: Double = 1.5811388300841898\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var rdd = sc.parallelize(1 to 1000);\n",
    "var counts = rdd.count();\n",
    "var fraction = 0.3\n",
    "def cointoss(x:Int): Boolean = scala.util.Random.nextFloat() <= fraction*1.2\n",
    "var myrdd = rdd.filter(cointoss)\n",
    "var samplesize = counts*fraction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var localsample = myrdd.take(samplesize.toInt)\n",
    "localsample.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(23, 34, 53, 56, 73, 74, 81, 86, 87, 91, 126, 130, 141, 153, 162, 185, 186, 193, 208, 239, 291, 294, 319, 321, 323, 326, 327, 331, 342, 345, 348, 352, 374, 377, 382, 387, 400, 432, 457, 464, 476, 480, 497, 542, 573, 574, 582, 619, 620, 641, 657, 659, 670, 672, 685, 695, 705, 719, 722, 724, 749, 750, 761, 763, 773, 788, 798, 802, 804, 805, 806, 830, 833, 850, 853, 867, 893, 894, 904, 938, 948, 951, 959, 971, 988, 994, 998)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4, 13, 38, 45, 49, 59, 72, 74, 83, 84, 85, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seq = sc.parallelize(1 to 100, 5);\n",
    "seq.sample(false, 0.1, 100000).collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(136, 425, 714)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = sc.parallelize(1 to 50, 3)\n",
    "def f(l:Iterator[Int]):Iterator[Int] = {\n",
    "    var sum = 0\n",
    "    while(l.hasNext){\n",
    "        sum = sum + l.next\n",
    "    }\n",
    "    return List(sum).iterator\n",
    "}\n",
    "\n",
    "rdd.mapPartitions(f).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.InterruptedException\n",
       "Message: null\n",
       "StackTrace: java.lang.Object.wait(Native Method)\n",
       "java.lang.Object.wait(Object.java:502)\n",
       "org.apache.spark.scheduler.JobWaiter.awaitResult(JobWaiter.scala:73)\n",
       "org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:559)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1921)\n",
       "org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:909)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)\n",
       "org.apache.spark.rdd.RDD.withScope(RDD.scala:310)\n",
       "org.apache.spark.rdd.RDD.collect(RDD.scala:908)\n",
       "$line40.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:20)\n",
       "$line40.$read$$iwC$$iwC$$iwC.<init>(<console>:25)\n",
       "$line40.$read$$iwC$$iwC.<init>(<console>:27)\n",
       "$line40.$read$$iwC.<init>(<console>:29)\n",
       "$line40.$read.<init>(<console>:31)\n",
       "$line40.$read$.<init>(<console>:35)\n",
       "$line40.$read$.<clinit>(<console>)\n",
       "$line40.$eval$.<init>(<console>:7)\n",
       "$line40.$eval$.<clinit>(<console>)\n",
       "$line40.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:497)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val rdd = sc.parallelize(1 to 50, 3)\n",
    "\n",
    "// The number of default partitions is a function of the following:\n",
    "// Are we running on hadoop?\n",
    "// Are we using sc.textFile\n",
    "// How many cores do we have?\n",
    "// How many machines do we have\n",
    "\n",
    "def f(l:Iterator[Int]):Iterator[Int] = {\n",
    "    var sum = 0\n",
    "    while(l.hasNext){\n",
    "        sum += 1;\n",
    "        l.next();\n",
    "    }\n",
    "    return List(sum).iterator\n",
    "}\n",
    "\n",
    "rdd.mapPartitions(f).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,3), (2,5), (a,1), (b,2), (d,4))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var tmp = List(('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5))\n",
    "var rdd = sc.parallelize(tmp)\n",
    "rdd.sortBy(x => x._1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(I walked down to the station with them, and then wandered through the streets of the little town, finally returning to the hotel, where I lay upon the sofa and tried to interest myself in a yellow-backed novel. The puny plot of the story was so thin, however, when compared to the deep mystery through which we were groping, and I found my attention wander so continually from the action to the fact, that I at last flung it across the room and gave myself up entirely to a consideration of the events of the day. Supposing that this unhappy young man's story were absolutely true, then what hellish thing, what absolutely unforeseen and extraordinary calamity could have occurred between the time when he parted from his father, and the moment when, drawn back by his ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var lines = sc.textFile(\"/data/mr/wordcount/input/\");\n",
    "var sortedbylength = lines.sortBy(_.length, false)\n",
    "sortedbylength.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var tmp = List((\"ab\",\"1\"),(\"c\",\"2\"),(\"bfgfg\",'0'));\n",
    "var rdd = sc.parallelize(tmp);\n",
    "var result = rdd.sortBy(x=>(x._1).length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((c,2), (ab,1), (bfgfg,0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__123_78910_456"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var myrdd = sc.parallelize(1 to 10, 3)\n",
    "var myrdd1 = myrdd.map(_.toString)\n",
    "\n",
    "def concat(s:String, n:String):String = s + n\n",
    "\n",
    "var s = \"_\"\n",
    "myrdd1.fold(s)(concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var rdd = sc.parallelize(1 to 100)\n",
    "\n",
    "var init = (0, 0) // sum, count\n",
    "def seq(t:(Int, Int), i:Int): (Int, Int) = (t._1 + i, t._2 + 1)\n",
    "def comb(t1:(Int, Int), t2:(Int, Int)): (Int, Int) = (t1._1 + t2._1, t1._2 + t2._2)\n",
    "\n",
    "var d = rdd.aggregate(init)(seq, comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5050,100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1, 2, 3, 4, 5, 6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(List(10, 1, 2, 9, 3, 4, 5, 6, 7)).takeOrdered(6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((10,SG), (9,AA), (7,ZZ), (6,DD), (5,AU), (4,RG))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var l = List((10, \"SG\"), (1, \"AS\"), (2, \"AB\"), (9, \"AA\"), (3, \"SS\"), (4, \"RG\"), (5, \"AU\"), (6, \"DD\"), (7, \"ZZ\"))\n",
    "var r = sc.parallelize(l)\n",
    "r.takeOrdered(6)(Ordering[Int].reverse.on(x => x._1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((7,ZZ), (3,SS), (10,SG), (4,RG), (6,DD), (5,AU))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.takeOrdered(6)(Ordering[String].reverse.on(x => x._2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((9,AA), (2,AB), (1,AS), (5,AU), (6,DD), (4,RG))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.takeOrdered(6)(Ordering[String].on(x => x._2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var myrdd = sc.parallelize(1 to 40, 4)\n",
    "\n",
    "def partitionSum(itr: Iterator[Int]) = \n",
    "    println(\"The sum of the parition is \" + itr.sum.toString)\n",
    "\n",
    "myrdd.foreachPartition(partitionSum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2, 3, 4, 5, 6, 7, 8, 9, 10, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var myrdd1 = myrdd.map( _ + 1)\n",
    "myrdd1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myrdd.foreach( _ + 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Say we have list url of images in a file\n",
    "// Download these urls into files using many computers\n",
    "\n",
    "// If I want get the output as error or success, map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>\n",
    "    // 1.How we can write the data to the Dbs by using foreachpartition\n",
    "\n",
    "    var myrdd = sc.parallelize(1 to 40, 4)\n",
    "\n",
    "    def saveToDB(itr: Iterator[Int]) = {\n",
    "        var connection = ConnectionManager.getConnection()\n",
    "        while( itr.hasNext()){\n",
    "            connection.executeQuery(\"insert into mytable values (??))\n",
    "        }\n",
    "    }\n",
    "    myrdd.foreachPartition(partitionSum)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key-Value RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,2), (1,3), (2,4), (1,6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var inputdata = List((1,2),(1,3),(2,4), (1, 6))\n",
    "var kvrdd = sc.parallelize(inputdata)\n",
    "kvrdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,XYZ), (2,XYZ), (3,XYZ), (4,XYZ), (5,XYZ), (6,XYZ), (7,XYZ), (8,XYZ), (9,XYZ), (10,XYZ), (11,XYZ), (12,XYZ), (13,XYZ), (14,XYZ), (15,XYZ), (16,XYZ), (17,XYZ), (18,XYZ), (19,XYZ), (20,XYZ), (21,XYZ), (22,XYZ), (23,XYZ), (24,XYZ), (25,XYZ), (26,XYZ), (27,XYZ), (28,XYZ), (29,XYZ), (30,XYZ))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mykvrdd = myrdd.map((_, \"XYZ\"))\n",
    "mykvrdd.take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,XYZ), (2,XYZ), (3,XYZ), (4,XYZ), (5,XYZ), (6,XYZ), (7,XYZ), (8,XYZ), (9,XYZ), (10,XYZ), (11,XYZ), (12,XYZ), (13,XYZ), (14,XYZ), (15,XYZ), (16,XYZ), (17,XYZ), (18,XYZ), (19,XYZ), (20,XYZ), (21,XYZ), (22,XYZ), (23,XYZ), (24,XYZ), (25,XYZ), (26,XYZ), (27,XYZ), (28,XYZ), (29,XYZ), (30,XYZ))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mykvrdd = myrdd.map( x => (x, \"XYZ\"))\n",
    "mykvrdd.take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sandeep"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Person(age:Int, name:String);\n",
    "var p = new Person(10, \"Sandeep\")\n",
    "p.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "var mypersonrdd = mykvrdd.map(t => new Person(t._1, t._2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(Person(1,XYZ), Person(2,XYZ), Person(3,XYZ), Person(4,XYZ), Person(5,XYZ), Person(6,XYZ), Person(7,XYZ), Person(8,XYZ), Person(9,XYZ), Person(10,XYZ))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypersonrdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var mynewkvrdd = mypersonrdd.map(p => p.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynewkvrdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
